import json
import boto3
import requests
import logging
import time
from datetime import datetime

# Configuración
BUCKET_NAME = "spaceflight-data-pipeline"
FOLDER_NAME = "raw"
API_BASE_URL = "https://api.spaceflightnewsapi.net/v4"
PAGE_SIZE = 100
TIMEOUT = 10
RATE_LIMIT_DELAY = 1  # Espera 1 segundo entre cada solicitud para evitar ser bloqueado.

# Inicializar clientes de AWS
s3 = boto3.client('s3')
eventbridge = boto3.client('events')

# Configuración de logs
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

def fetch_paginated_data(endpoint):
    """Obtiene datos paginados desde la API con manejo de paginación y rate limits."""
    start = 0
    page_count = 0
    all_data = []

    while True:
        url = f"{API_BASE_URL}/{endpoint}?_limit={PAGE_SIZE}&_start={start}"
        try:
            logging.info(f"Solicitando datos de {url}")
            response = requests.get(url, timeout=TIMEOUT)
            response.raise_for_status()
            page_data = response.json()

            # Validación de la respuesta
            if not isinstance(page_data, dict) or 'results' not in page_data:
                logging.warning(f"Formato de respuesta inesperado en {url}")
                break

            results = page_data['results']
            if not results:
                logging.info(f"No hay más datos en {endpoint}. Páginas procesadas: {page_count}")
                break

            # Deduplicación de datos (por ejemplo, basado en 'id')
            unique_results = deduplicate_data(results)
            
            # Guardar resultados en S3
            save_to_s3(unique_results, f"{endpoint}_page_{start}")

            all_data.extend(unique_results)
            page_count += 1
            start += PAGE_SIZE
            logging.info(f"Página {page_count} de {endpoint} procesada con éxito.")

            # Simulación de manejo de rate limits
            time.sleep(RATE_LIMIT_DELAY)

            # Limitar a 5 páginas para pruebas
            if page_count >= 5:
                logging.info("Se ha alcanzado el límite de 5 páginas para pruebas.")
                break

        except requests.exceptions.RequestException as e:
            logging.error(f"Error al obtener datos de {url}: {str(e)}")
            break
    
    return all_data

def deduplicate_data(data):
    """Deduplica los datos basándose en el campo 'id'."""
    seen_ids = set()
    deduplicated_data = []

    for item in data:
        item_id = item.get('id')
        if item_id not in seen_ids:
            seen_ids.add(item_id)
            deduplicated_data.append(item)
        else:
            logging.warning(f"Artículo duplicado encontrado: id={item_id}")

    return deduplicated_data

def save_to_s3(data, key):
    """Guarda los datos en S3 como archivo JSON."""
    try:
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
        key = f"{FOLDER_NAME}/{key}_{timestamp}.json"
        s3.put_object(Bucket=BUCKET_NAME, Key=key, Body=json.dumps(data))
        logging.info(f"Datos guardados en S3: {key}")
    except Exception as e:
        logging.error(f"Error guardando datos en S3: {str(e)}")

def send_event_to_eventbridge():
    """Envía un evento a EventBridge indicando que la ingesta ha finalizado."""
    try:
        response = eventbridge.put_events(
            Entries=[
                {
                    'Source': 'spaceflight-data-ingestion',
                    'DetailType': 'IngestionCompleted',
                    'Detail': json.dumps({
                        "message": "Ingesta completada con éxito",
                        "bucket": BUCKET_NAME,
                        "path": f"s3://{BUCKET_NAME}/{FOLDER_NAME}"
                    }),
                    'EventBusName': 'default'
                }
            ]
        )
        logging.info(f"Evento enviado a EventBridge: {response}")
    except Exception as e:
        logging.error(f"Error al enviar evento a EventBridge: {str(e)}")

def lambda_handler(event, context):
    """Manejador de AWS Lambda."""
    endpoints = ["articles", "blogs", "reports"]

    for endpoint in endpoints:
        logging.info(f"Procesando datos de {endpoint}...")
        fetch_paginated_data(endpoint)

    # Enviar evento a EventBridge
    send_event_to_eventbridge()

    return {
        "statusCode": 200,
        "body": json.dumps("Ingestión completada y evento enviado a EventBridge.")
    }
