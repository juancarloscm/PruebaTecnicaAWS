# üìÑ Documento T√©cnico del Proyecto SpaceFlight Data Pipeline

## **1Ô∏è‚É£ Estimaci√≥n de Volumen de Datos** üìä  

### **Datos Crudos (API SpaceFlight News)**
- **Tipo de datos:** JSON  
- **Tama√±o promedio por art√≠culo:** 1 KB ‚Äì 5 KB  
- **Estimaci√≥n diaria:**  
  - *Articles:* ~1,000 registros/d√≠a  
  - *Blogs:* ~500 registros/d√≠a  
  - *Reports:* ~300 registros/d√≠a  
- **Volumen total estimado:**  
  - **Diario:** ~2 MB ‚Äì 5 MB  
  - **Mensual:** ~60 MB ‚Äì 150 MB  
  - **Anual:** ~720 MB ‚Äì 1.8 GB  

### **Datos Procesados (Parquet)**
- **Formato:** Parquet, particionado por `published_date`  
- **Reducci√≥n de tama√±o:** ~70% en comparaci√≥n con JSON  
- **Volumen estimado procesado:**  
  - **Diario:** ~1 MB ‚Äì 3 MB  
  - **Mensual:** ~30 MB ‚Äì 90 MB  
  - **Anual:** ~360 MB ‚Äì 1.1 GB  

---

## **2Ô∏è‚É£ Estrategia de Almacenamiento y B√∫squeda** üì¶  

### **Almacenamiento**
- **Amazon S3**
  - **Bucket `spaceflight-data-pipeline`:** Almacena los datos crudos (`raw/`) y procesados (`processed/`).  
  - **Bucket `spaceflight-data-results`:** Almacena los resultados de consultas de Athena para visualizaci√≥n en Looker Studio.  

- **AWS Glue Catalog**
  - **Estructura del esquema:** Define tablas para facilitar las consultas SQL con Athena.  
    - `dim_news_source`: Informaci√≥n de fuentes de noticias.  
    - `dim_topic`: Clasificaci√≥n por temas.  
    - `fact_article`: Datos detallados de los art√≠culos, particionados por fecha (`published_date`).  

### **B√∫squeda y Consulta**
- **Amazon Athena**
  - Consultas SQL sobre los datos procesados en formato Parquet.  
  - **Particionamiento:** Mejora el rendimiento al limitar las consultas por `published_date`.  

---

## **3Ô∏è‚É£ Plan de Contingencia** ‚ö†Ô∏è  

### **Backup y Recuperaci√≥n**
1. **Backup Autom√°tico:**  
   - Copias de seguridad peri√≥dicas del bucket `processed/` a otro bucket en una **regi√≥n secundaria** de AWS.  

2. **Recuperaci√≥n:**  
   - Restauraci√≥n r√°pida desde el bucket de respaldo en caso de p√©rdida de datos o corrupci√≥n.  
   - **Comando para actualizar las particiones:**  
     ```bash
     MSCK REPAIR TABLE fact_article;
     ```

### **Gesti√≥n de Errores en el Pipeline**
- **Lambda y Glue Job:** Configuraci√≥n de reintentos autom√°ticos.  
- **EventBridge:** Notificaci√≥n de errores cr√≠ticos a **Amazon CloudWatch** para activar alertas.  

---

## **4Ô∏è‚É£ Sistema de Monitoreo** üìà  

### **Amazon CloudWatch**
- **Monitoreo de Lambda:** Logs de ejecuci√≥n, tiempos de respuesta y errores.  
- **Glue Job Logs:** Logs del Spark UI para analizar el proceso de transformaci√≥n de datos.  
- **Alerta de Errores:** Configuraci√≥n de alertas en CloudWatch que notifican por correo electr√≥nico o Slack en caso de fallos.  

### **Amazon S3 Metrics**
- Monitoreo del uso de almacenamiento, accesos y tasas de error.  

### **Amazon Athena Query History**
- Historial de consultas para identificar consultas lentas o mal optimizadas.  

---

## **Conclusi√≥n y Siguientes Pasos**
El pipeline est√° dise√±ado para manejar vol√∫menes de datos moderados con escalabilidad en AWS. El sistema de monitoreo y el plan de contingencia garantizan una operaci√≥n confiable y recuperaci√≥n r√°pida en caso de fallos.

### **Siguientes Pasos:**
1. Automatizaci√≥n completa del pipeline con **Airflow DAG**.
2. Optimizaci√≥n de consultas en Athena para mejorar el rendimiento.
3. Mejora de la visualizaci√≥n en Looker Studio para agregar gr√°ficos adicionales y alertas de tendencias.

---
¬°Gracias por leer! üòä

